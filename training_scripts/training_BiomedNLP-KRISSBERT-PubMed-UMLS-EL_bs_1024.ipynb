{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4522fcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "2022-11-07 10:42:06.687513: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-07 10:42:06.871525: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import nlp\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import wget\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "import regex as re\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "import random\n",
    "import copy\n",
    "import warnings\n",
    "import json\n",
    "from collections import defaultdict\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6db097cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [..........................................................................] 2448432 / 2448432"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'nfcorpus.zip'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'nfcorpus'\n",
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(dataset)\n",
    "wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d63556",
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip nfcorpus.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a1c9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MED-10</td>\n",
       "      <td>Statin Use and Breast Cancer Survival: A Natio...</td>\n",
       "      <td>Recent studies have suggested that statins, an...</td>\n",
       "      <td>{'url': 'http://www.ncbi.nlm.nih.gov/pubmed/25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MED-14</td>\n",
       "      <td>Statin use after diagnosis of breast cancer an...</td>\n",
       "      <td>BACKGROUND: Preclinical studies have shown tha...</td>\n",
       "      <td>{'url': 'http://www.ncbi.nlm.nih.gov/pubmed/25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MED-118</td>\n",
       "      <td>Alkylphenols in human milk and their relations...</td>\n",
       "      <td>The aims of this study were to determine the c...</td>\n",
       "      <td>{'url': 'http://www.ncbi.nlm.nih.gov/pubmed/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MED-301</td>\n",
       "      <td>Methylmercury: A Potential Environmental Risk ...</td>\n",
       "      <td>Epilepsy or seizure disorder is one of the mos...</td>\n",
       "      <td>{'url': 'http://www.ncbi.nlm.nih.gov/pubmed/22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MED-306</td>\n",
       "      <td>Sensitivity of Continuous Performance Test (CP...</td>\n",
       "      <td>Hit Reaction Time latencies (HRT) in the Conti...</td>\n",
       "      <td>{'url': 'http://www.ncbi.nlm.nih.gov/pubmed/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3628</th>\n",
       "      <td>MED-917</td>\n",
       "      <td>Effect of freezing and storage on the phenolic...</td>\n",
       "      <td>Scottish-grown red raspberries are a rich sour...</td>\n",
       "      <td>{'url': 'http://www.ncbi.nlm.nih.gov/pubmed/12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3629</th>\n",
       "      <td>MED-941</td>\n",
       "      <td>Topical vitamin A treatment of recalcitrant co...</td>\n",
       "      <td>BACKGROUND: Common warts (verruca vulgaris) ar...</td>\n",
       "      <td>{'url': 'http://www.ncbi.nlm.nih.gov/pubmed?te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3630</th>\n",
       "      <td>MED-942</td>\n",
       "      <td>Esophageal injury by apple cider vinegar table...</td>\n",
       "      <td>Apple cider vinegar products are advertised in...</td>\n",
       "      <td>{'url': 'http://www.ncbi.nlm.nih.gov/pubmed/15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>MED-952</td>\n",
       "      <td>Cannabis and the lung.</td>\n",
       "      <td>The use of cannabis is embedded within many so...</td>\n",
       "      <td>{'url': 'http://www.ncbi.nlm.nih.gov/pubmed/21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>MED-961</td>\n",
       "      <td>Vitamin D(3) is more potent than vitamin D(2) ...</td>\n",
       "      <td>BACKGROUND: Current unitage for the calciferol...</td>\n",
       "      <td>{'url': 'http://www.ncbi.nlm.nih.gov/pubmed/21...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3633 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          _id                                              title  \\\n",
       "0      MED-10  Statin Use and Breast Cancer Survival: A Natio...   \n",
       "1      MED-14  Statin use after diagnosis of breast cancer an...   \n",
       "2     MED-118  Alkylphenols in human milk and their relations...   \n",
       "3     MED-301  Methylmercury: A Potential Environmental Risk ...   \n",
       "4     MED-306  Sensitivity of Continuous Performance Test (CP...   \n",
       "...       ...                                                ...   \n",
       "3628  MED-917  Effect of freezing and storage on the phenolic...   \n",
       "3629  MED-941  Topical vitamin A treatment of recalcitrant co...   \n",
       "3630  MED-942  Esophageal injury by apple cider vinegar table...   \n",
       "3631  MED-952                             Cannabis and the lung.   \n",
       "3632  MED-961  Vitamin D(3) is more potent than vitamin D(2) ...   \n",
       "\n",
       "                                                   text  \\\n",
       "0     Recent studies have suggested that statins, an...   \n",
       "1     BACKGROUND: Preclinical studies have shown tha...   \n",
       "2     The aims of this study were to determine the c...   \n",
       "3     Epilepsy or seizure disorder is one of the mos...   \n",
       "4     Hit Reaction Time latencies (HRT) in the Conti...   \n",
       "...                                                 ...   \n",
       "3628  Scottish-grown red raspberries are a rich sour...   \n",
       "3629  BACKGROUND: Common warts (verruca vulgaris) ar...   \n",
       "3630  Apple cider vinegar products are advertised in...   \n",
       "3631  The use of cannabis is embedded within many so...   \n",
       "3632  BACKGROUND: Current unitage for the calciferol...   \n",
       "\n",
       "                                               metadata  \n",
       "0     {'url': 'http://www.ncbi.nlm.nih.gov/pubmed/25...  \n",
       "1     {'url': 'http://www.ncbi.nlm.nih.gov/pubmed/25...  \n",
       "2     {'url': 'http://www.ncbi.nlm.nih.gov/pubmed/20...  \n",
       "3     {'url': 'http://www.ncbi.nlm.nih.gov/pubmed/22...  \n",
       "4     {'url': 'http://www.ncbi.nlm.nih.gov/pubmed/20...  \n",
       "...                                                 ...  \n",
       "3628  {'url': 'http://www.ncbi.nlm.nih.gov/pubmed/12...  \n",
       "3629  {'url': 'http://www.ncbi.nlm.nih.gov/pubmed?te...  \n",
       "3630  {'url': 'http://www.ncbi.nlm.nih.gov/pubmed/15...  \n",
       "3631  {'url': 'http://www.ncbi.nlm.nih.gov/pubmed/21...  \n",
       "3632  {'url': 'http://www.ncbi.nlm.nih.gov/pubmed/21...  \n",
       "\n",
       "[3633 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read corpus\n",
    "df_corpus = pd.read_json('nfcorpus/corpus.jsonl', lines=True)\n",
    "df_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "232daaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id_to_idx = {}\n",
    "for idx, row in df_corpus.iterrows():\n",
    "    doc_id = row['_id']\n",
    "    doc_id_to_idx[doc_id] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fab80089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PLAIN-3</td>\n",
       "      <td>Breast Cancer Cells Feed on Cholesterol</td>\n",
       "      <td>{'url': 'http://nutritionfacts.org/2015/07/14/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PLAIN-4</td>\n",
       "      <td>Using Diet to Treat Asthma and Eczema</td>\n",
       "      <td>{'url': 'http://nutritionfacts.org/2015/07/09/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLAIN-5</td>\n",
       "      <td>Treating Asthma With Plants vs. Pills</td>\n",
       "      <td>{'url': 'http://nutritionfacts.org/2015/07/07/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PLAIN-6</td>\n",
       "      <td>How Fruits and Vegetables Can Treat Asthma</td>\n",
       "      <td>{'url': 'http://nutritionfacts.org/2015/07/02/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PLAIN-7</td>\n",
       "      <td>How Fruits and Vegetables Can Prevent Asthma</td>\n",
       "      <td>{'url': 'http://nutritionfacts.org/2015/06/30/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>PLAIN-3432</td>\n",
       "      <td>Healthy Chocolate Milkshakes</td>\n",
       "      <td>{'url': 'http://nutritionfacts.org/video/healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>PLAIN-3442</td>\n",
       "      <td>The Healthiest Vegetables</td>\n",
       "      <td>{'url': 'http://nutritionfacts.org/video/the-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3234</th>\n",
       "      <td>PLAIN-3452</td>\n",
       "      <td>Bowel Movement Frequency</td>\n",
       "      <td>{'url': 'http://nutritionfacts.org/video/bowel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>PLAIN-3462</td>\n",
       "      <td>Olive Oil and Artery Function</td>\n",
       "      <td>{'url': 'http://nutritionfacts.org/video/olive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3236</th>\n",
       "      <td>PLAIN-3472</td>\n",
       "      <td>How Doctors Responded to Being Named a Leading...</td>\n",
       "      <td>{'url': 'http://nutritionfacts.org/video/how-d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3237 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             _id                                               text  \\\n",
       "0        PLAIN-3            Breast Cancer Cells Feed on Cholesterol   \n",
       "1        PLAIN-4              Using Diet to Treat Asthma and Eczema   \n",
       "2        PLAIN-5              Treating Asthma With Plants vs. Pills   \n",
       "3        PLAIN-6         How Fruits and Vegetables Can Treat Asthma   \n",
       "4        PLAIN-7       How Fruits and Vegetables Can Prevent Asthma   \n",
       "...          ...                                                ...   \n",
       "3232  PLAIN-3432                       Healthy Chocolate Milkshakes   \n",
       "3233  PLAIN-3442                          The Healthiest Vegetables   \n",
       "3234  PLAIN-3452                           Bowel Movement Frequency   \n",
       "3235  PLAIN-3462                      Olive Oil and Artery Function   \n",
       "3236  PLAIN-3472  How Doctors Responded to Being Named a Leading...   \n",
       "\n",
       "                                               metadata  \n",
       "0     {'url': 'http://nutritionfacts.org/2015/07/14/...  \n",
       "1     {'url': 'http://nutritionfacts.org/2015/07/09/...  \n",
       "2     {'url': 'http://nutritionfacts.org/2015/07/07/...  \n",
       "3     {'url': 'http://nutritionfacts.org/2015/07/02/...  \n",
       "4     {'url': 'http://nutritionfacts.org/2015/06/30/...  \n",
       "...                                                 ...  \n",
       "3232  {'url': 'http://nutritionfacts.org/video/healt...  \n",
       "3233  {'url': 'http://nutritionfacts.org/video/the-h...  \n",
       "3234  {'url': 'http://nutritionfacts.org/video/bowel...  \n",
       "3235  {'url': 'http://nutritionfacts.org/video/olive...  \n",
       "3236  {'url': 'http://nutritionfacts.org/video/how-d...  \n",
       "\n",
       "[3237 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read corpus\n",
    "df_queries = pd.read_json('nfcorpus/queries.jsonl', lines=True)\n",
    "df_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7142f5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id_to_idx = {}\n",
    "for idx, row in df_queries.iterrows():\n",
    "    query_id = row['_id']\n",
    "    query_id_to_idx[query_id] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b52ba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'microsoft/BiomedNLP-KRISSBERT-PubMed-UMLS-EL'\n",
    "learning_rate = 5e-4\n",
    "epochs = 10\n",
    "batch_size=1024\n",
    "batch_size_val = 512\n",
    "checkpoint_batch_size = 64\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5a270e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batches in such as way that in each batch a query/document can occur in atmost only one of the samples\n",
    "\n",
    "def get_batch(queries, doc_matrix, batch_size):\n",
    "    batch = []\n",
    "    b_docs = set()\n",
    "    i = 0\n",
    "    \n",
    "    while(len(batch) < batch_size and i<len(doc_matrix)):\n",
    "        query = queries[i]\n",
    "        for j in range(len(doc_matrix[i])):\n",
    "            doc = doc_matrix[i][j]\n",
    "            if doc not in b_docs:\n",
    "                batch.append([query, doc])\n",
    "                b_docs.add(doc)\n",
    "                doc_matrix[i].pop(j)\n",
    "                break\n",
    "        i += 1 \n",
    "    return batch \n",
    "\n",
    "def find_diff_sample(b_queries, b_docs, trash, qrel, total_rel_list):\n",
    "    for i, (q, d) in enumerate(trash):\n",
    "        if q not in b_queries and d not in b_docs:\n",
    "            trash.remove((q, d))\n",
    "            return [q, d]\n",
    "    \n",
    "    qrel_list = list(qrel.items())\n",
    "    idx1 = random.randint(0, len(qrel_list)-1)\n",
    "    \n",
    "    for i in range(idx1, idx1+len(qrel_list)):\n",
    "        (query, docs)= qrel_list[i%len(qrel_list)]\n",
    "#     for (query, docs) in qrel.items():\n",
    "        if query not in b_queries:\n",
    "            idx2 = random.randint(0, len(docs)-1)\n",
    "            for j in range(idx2, idx2+len(docs)):\n",
    "                doc = docs[j%len(docs)]\n",
    "                if doc not in b_docs:\n",
    "                    return [query, doc]\n",
    "    return None\n",
    "        \n",
    "def get_dataset(qrel, total_rel_list, batch_size, extend=True, seed=42):\n",
    "    items = list(qrel.items())\n",
    "    random.Random(seed).shuffle(items)\n",
    "    qrel = dict(items)\n",
    "    qrel_copy = copy.deepcopy(qrel)\n",
    "        \n",
    "    queries = list(qrel.keys())\n",
    "    doc_matrix = list(qrel.values())\n",
    "        \n",
    "    dataset = []\n",
    "    last_batch = []\n",
    "    while(True):\n",
    "        batch = get_batch(queries, doc_matrix, batch_size)\n",
    "        if len(batch) < batch_size:\n",
    "            last_batch = batch\n",
    "            break\n",
    "        dataset.extend(batch)\n",
    "                    \n",
    "    if extend:\n",
    "        rel_list = []\n",
    "        for query, docs in zip(queries, doc_matrix):\n",
    "            for doc in docs:\n",
    "                rel_list.append([query, doc])\n",
    "\n",
    "        random.Random(seed).shuffle(rel_list)\n",
    "        random.seed(seed)\n",
    "\n",
    "        trash = set()\n",
    "        for i in tqdm(range(0, len(rel_list), batch_size), ncols=80):\n",
    "            batch = rel_list[i: i+batch_size]\n",
    "            b_queries, b_docs = [], []\n",
    "            for j in range(len(batch)):\n",
    "                [query, doc] = batch[j]\n",
    "                if query in b_queries or doc in b_docs:\n",
    "                    trash.add((query, doc))\n",
    "                    batch[j] = find_diff_sample(b_queries, b_docs, trash, qrel_copy, total_rel_list)\n",
    "                b_queries.append(batch[j][0])\n",
    "                b_docs.append(batch[j][1])\n",
    "\n",
    "            if len(batch) == batch_size:\n",
    "                dataset.extend(batch)\n",
    "                    \n",
    "    dataset.extend(last_batch)\n",
    "    return dataset\n",
    "\n",
    "def get_qrel(split='train', batch_size=2048, extend=True, return_dict=True):\n",
    "    path = f'nfcorpus/qrels/{split}.tsv'\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    \n",
    "    qrel = defaultdict(list)\n",
    "    total_rel_list = []\n",
    "    for _, row in df.iterrows():\n",
    "        qrel[row['query-id']].append(row['corpus-id'])\n",
    "        total_rel_list.append([row['query-id'], row['corpus-id']])\n",
    "            \n",
    "    return get_dataset(qrel, total_rel_list, batch_size, extend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c939fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "affa31d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [32:03<00:00, 27.48s/it]\n"
     ]
    }
   ],
   "source": [
    "train_data = get_qrel(split='train', batch_size=batch_size)\n",
    "with open(\"train_data.json\", \"w\") as fp:\n",
    "    json.dump(train_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfb3762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_data.json\", \"r\") as fp:\n",
    "    train_data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b77c85c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = get_qrel(split='dev', batch_size=128, extend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebc73dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFCorpusDataset(Dataset):\n",
    "    def __init__(self, df_corpus, df_queries, doc_id_to_idx, query_id_to_idx, query_doc_list, min_doc_length=200, training=True):\n",
    "        self.df_corpus = df_corpus\n",
    "        self.df_queries = df_queries\n",
    "        self.doc_id_to_idx = doc_id_to_idx\n",
    "        self.query_id_to_idx = query_id_to_idx\n",
    "        self.query_doc_list = query_doc_list\n",
    "        self.min_doc_length = min_doc_length\n",
    "        self.training = training\n",
    "        self.n_samples = len(query_doc_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        [query_id, doc_id] = self.query_doc_list[index]\n",
    "        q_row = df_queries.iloc[self.query_id_to_idx[query_id]]\n",
    "        d_row = df_corpus.iloc[self.doc_id_to_idx[doc_id]]\n",
    "        \n",
    "        query = q_row['text']\n",
    "        doc_title = d_row['title']\n",
    "        doc_text = d_row['text']\n",
    "\n",
    "        if self.training:\n",
    "            doc_text = doc_text.split()\n",
    "            doc_span_len = len(doc_text)\n",
    "            if doc_span_len > self.min_doc_length:\n",
    "                doc_span_len = random.randint(self.min_doc_length, len(doc_text)) \n",
    "            doc_text = doc_text[:doc_span_len]\n",
    "            doc_text = ' '.join(doc_text)\n",
    "        \n",
    "        doc = f'{doc_title} {doc_text}'\n",
    "        \n",
    "        return (query, doc)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71881604",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NFCorpusDataset(df_corpus, df_queries, doc_id_to_idx, query_id_to_idx, train_data, training=True)\n",
    "validation_dataset = NFCorpusDataset(df_corpus, df_queries, doc_id_to_idx, query_id_to_idx, val_data, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e46ae7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrieverModelBertBased(nn.Module):\n",
    "    def __init__(self, encoder_name):\n",
    "        super(RetrieverModelBertBased, self).__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(encoder_name)\n",
    "        self.encoder_output_dim = 768\n",
    "        self.projection_output_dim = 128\n",
    "        self.query_projection_layer = nn.Linear(self.encoder_output_dim, self.projection_output_dim, bias=False)\n",
    "        self.doc_projection_layer = nn.Linear(self.encoder_output_dim, self.projection_output_dim, bias=False)\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "    def encode(self, input_ids, attention_mask, checkpoint_batch_size):\n",
    "        if checkpoint_batch_size == None or input_ids.shape[0] < checkpoint_batch_size:\n",
    "            return self.encoder(input_ids, attention_mask)['pooler_output']\n",
    "\n",
    "        device = input_ids.device\n",
    "        input_shape = input_ids.size()\n",
    "        token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
    "        head_mask = [None] * self.encoder.config.num_hidden_layers\n",
    "        extended_attention_mask: torch.Tensor = self.encoder.get_extended_attention_mask(\n",
    "            attention_mask, input_shape, device\n",
    "        )\n",
    "\n",
    "        def partial_encode(*inputs):\n",
    "            encoder_outputs = self.encoder.encoder(inputs[0], attention_mask=inputs[1], head_mask=head_mask,)\n",
    "            sequence_output = encoder_outputs[0]\n",
    "            pooled_output = self.encoder.pooler(sequence_output)\n",
    "            return pooled_output\n",
    "\n",
    "        embedding_output = self.encoder.embeddings(\n",
    "            input_ids=input_ids, position_ids=None, token_type_ids=token_type_ids, inputs_embeds=None\n",
    "        )\n",
    "\n",
    "        pooled_output_list = []\n",
    "        for b in range(math.ceil(input_ids.shape[0] / checkpoint_batch_size)):\n",
    "            b_embedding_output = embedding_output[b * checkpoint_batch_size : (b + 1) * checkpoint_batch_size]\n",
    "            b_attention_mask = extended_attention_mask[b * checkpoint_batch_size : (b + 1) * checkpoint_batch_size]\n",
    "            pooled_output = checkpoint.checkpoint(partial_encode, b_embedding_output, b_attention_mask)\n",
    "            pooled_output_list.append(pooled_output)\n",
    "        return torch.cat(pooled_output_list, dim=0)\n",
    "\n",
    "    def project_queries(self, query_ids, query_mask, checkpoint_batch_size):\n",
    "        query_encoding = self.encode(query_ids, query_mask, checkpoint_batch_size)\n",
    "        query_projection = self.query_projection_layer(query_encoding)\n",
    "        return query_projection\n",
    "\n",
    "    def project_docs(self, doc_ids, doc_mask, checkpoint_batch_size):\n",
    "        doc_encoding = self.encode(doc_ids, doc_mask, checkpoint_batch_size)\n",
    "        doc_projection = self.doc_projection_layer(doc_encoding)\n",
    "        return doc_projection\n",
    "\n",
    "    def forward(self, query_ids, query_mask, doc_ids, doc_mask, checkpoint_batch_size):\n",
    "        query_projection = self.project_queries(query_ids, query_mask, checkpoint_batch_size)\n",
    "        doc_projection = self.project_docs(doc_ids, doc_mask, checkpoint_batch_size)\n",
    "        dot_product_scores = torch.mm(query_projection, doc_projection.t())\n",
    "\n",
    "        batch_size = dot_product_scores.shape[0]\n",
    "        labels = torch.arange(batch_size).to(device)\n",
    "        loss1 = self.cross_entropy_loss(dot_product_scores, labels)\n",
    "        loss2 = self.cross_entropy_loss(dot_product_scores.t(), labels)\n",
    "        return (loss1+loss2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "236a7452",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def create_batch(query_docs_batch):\n",
    "    queries = []\n",
    "    docs = []\n",
    "    for query, doc in query_docs_batch:\n",
    "        queries.append(query)\n",
    "        docs.append(doc)\n",
    "    \n",
    "    tokenized_queries = tokenizer(queries, max_length = 32, padding='max_length', truncation = True)\n",
    "    tokenized_docs = tokenizer(docs, max_length = 256, padding='max_length', truncation = True)\n",
    "\n",
    "    query_ids = torch.LongTensor(tokenized_queries[\"input_ids\"]).to(device)\n",
    "    query_mask = torch.LongTensor(tokenized_queries[\"attention_mask\"]).to(device)\n",
    "    doc_ids = torch.LongTensor(tokenized_docs[\"input_ids\"]).to(device)\n",
    "    doc_mask = torch.LongTensor(tokenized_docs[\"attention_mask\"]).to(device)\n",
    "\n",
    "    return (query_ids, query_mask, doc_ids, doc_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d4ecbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_model = RetrieverModelBertBased(model_name)\n",
    "retriever_model.to(device)\n",
    "optimizer = AdamW(retriever_model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=100,\n",
    "        num_training_steps=(epochs + 1) * math.ceil(len(train_dataset) / batch_size),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1914170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109681152\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in retriever_model.parameters() if p.requires_grad)\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b10c55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_retrieval_model(epochs, previously_completed_epochs=0):\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        retriever_model.train()\n",
    "        data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=create_batch)\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        with tqdm(data_loader, unit='batch', dynamic_ncols=True, bar_format='{desc}{percentage:3.0f}%|{bar:5}{r_bar}') as data_loader_tqdm:\n",
    "            for batch_num, batch in enumerate(data_loader_tqdm):\n",
    "                data_loader_tqdm.set_description(f'Epoch {epoch+1}/{epochs} (T)')\n",
    "\n",
    "                question_ids, question_mask, answer_ids, answer_mask = batch\n",
    "                loss = retriever_model(question_ids, question_mask, answer_ids, answer_mask, checkpoint_batch_size)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                retriever_model.zero_grad()\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                data_loader_tqdm.set_postfix(avg_loss=round(running_loss/(batch_num+1), 4))\n",
    "                \n",
    "        # Saving the model\n",
    "        model_dict = {\n",
    "            'model': retriever_model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(),\n",
    "        }\n",
    "        torch.save(model_dict, f'./BiomedNLP-KRISSBERT-PubMed-UMLS-EL_epochwise_bs_1024/retriever_BiomedNLP-KRISSBERT-PubMed-UMLS-EL_bs_1024_epoch_{previously_completed_epochs+epoch+1}.pth')\n",
    "\n",
    "        # Validation\n",
    "        retriever_model.eval()\n",
    "        validation_data_loader = DataLoader(validation_dataset, batch_size=batch_size_val, shuffle=False, collate_fn=create_batch)\n",
    "        running_validation_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with tqdm(validation_data_loader, unit='batch', dynamic_ncols=True, bar_format='{desc}{percentage:3.0f}%|{bar:5}{r_bar}') as data_loader_tqdm:\n",
    "                for batch_num, batch in enumerate(data_loader_tqdm):\n",
    "                    data_loader_tqdm.set_description(f'Epoch {epoch+1}/{epochs} (V)')\n",
    "                    question_ids, question_mask, answer_ids, answer_mask = batch\n",
    "                    loss = retriever_model(question_ids, question_mask, answer_ids, answer_mask, checkpoint_batch_size=None)\n",
    "                    running_validation_loss += loss.item()\n",
    "\n",
    "                    data_loader_tqdm.set_postfix(avg_val_loss=round(running_validation_loss/(batch_num+1), 4))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8dd44f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 (T): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [37:36<00:00, 20.90s/batch, avg_loss=6.01]\n",
      "Epoch 1/10 (V): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:27<00:00,  2.53s/batch, avg_val_loss=5.36]\n",
      "Epoch 2/10 (T): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [37:35<00:00, 20.89s/batch, avg_loss=4.67]\n",
      "Epoch 2/10 (V): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:27<00:00,  2.53s/batch, avg_val_loss=5.39]\n",
      "Epoch 3/10 (T): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [37:36<00:00, 20.89s/batch, avg_loss=4.01]\n",
      "Epoch 3/10 (V): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:27<00:00,  2.53s/batch, avg_val_loss=5.49]\n",
      "Epoch 4/10 (T): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [37:36<00:00, 20.90s/batch, avg_loss=3.67]\n",
      "Epoch 4/10 (V): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:27<00:00,  2.53s/batch, avg_val_loss=5.8] \n",
      "Epoch 5/10 (T): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [37:37<00:00, 20.90s/batch, avg_loss=3.46]\n",
      "Epoch 5/10 (V): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:27<00:00,  2.53s/batch, avg_val_loss=5.94]\n",
      "Epoch 6/10 (T): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [37:33<00:00, 20.87s/batch, avg_loss=3.29]\n",
      "Epoch 6/10 (V): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:27<00:00,  2.53s/batch, avg_val_loss=5.93]\n",
      "Epoch 7/10 (T): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [37:33<00:00, 20.87s/batch, avg_loss=3.16]\n",
      "Epoch 7/10 (V): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:27<00:00,  2.53s/batch, avg_val_loss=6.14]\n",
      "Epoch 8/10 (T): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [37:33<00:00, 20.87s/batch, avg_loss=3.04]\n",
      "Epoch 8/10 (V): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:27<00:00,  2.53s/batch, avg_val_loss=6.21]\n",
      "Epoch 9/10 (T): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [37:34<00:00, 20.87s/batch, avg_loss=2.95]\n",
      "Epoch 9/10 (V): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:27<00:00,  2.52s/batch, avg_val_loss=6.21]\n",
      "Epoch 10/10 (T): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [37:33<00:00, 20.86s/batch, avg_loss=2.88]\n",
      "Epoch 10/10 (V): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:27<00:00,  2.52s/batch, avg_val_loss=6.27]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train_retrieval_model(epochs=10)\n",
    "except KeyboardInterrupt:\n",
    "    print('\\nTraining Interrupted!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3f71e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './BiomedNLP-KRISSBERT-PubMed-UMLS-EL_epochwise_bs_1024/retriever_BiomedNLP-KRISSBERT-PubMed-UMLS-EL_bs_1024_epoch_{previously_completed_epochs+epoch+1}.pth'\n",
    "saved_checkpoint = torch.load(PATH)\n",
    "retriever_model.load_state_dict(saved_checkpoint['model'])\n",
    "optimizer.load_state_dict(saved_checkpoint['optimizer'])\n",
    "scheduler.load_state_dict(saved_checkpoint['scheduler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327744f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
